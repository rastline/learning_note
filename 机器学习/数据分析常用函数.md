# 一、Pandas

## 1、Series对象

### 1.1 map()

​	map()的主要任务用于映射具有公共列的两个系列的值。要映射两个系列, 第一个系列的最后一列应与第二个系列的索引列相同, 并且值应唯一。

> 即根据参数进行相应的处理，比如执行函数的逻辑，或map根据索引进行映射

```Python
Series.map(arg, na_action=None)
参数
  arg：函数, 字典或系列。它指的是映射对应关系。
	na_action：{无, ‘忽略’}, 默认值无。如果忽略, 它将返回空值, 而不将其传递给映射对应关系。
return
	它返回具有与调用者相同索引的Pandas系列。
```

demo:

```python 
import pandas as pd
from pandas import Series, DataFrame
 
data = DataFrame({'food':['bacon','pulled pork','bacon','Pastrami',
            'corned beef','Bacon','pastrami','honey ham','nova lox'],
                  'ounces':[4,3,12,6,7.5,8,3,5,6]})
meat_to_animal = {
    'bacon':'pig',
    'pulled pork':'pig',
    'pastrami':'cow',
    'corned beef':'cow',
    'honey ham':'pig',
    'nova lox':'salmon'    }  
 
data['animal'] = data['food'].map(str.lower).map(meat_to_animal) 
print(data) 
print("============================================")
data['food'].map(lambda x: meat_to_animal[x.lower()])  
print(data)

# 打印结果
          food  ounces  animal
0        bacon     4.0     pig
1  pulled pork     3.0     pig
2        bacon    12.0     pig
3     Pastrami     6.0     cow
4  corned beef     7.5     cow
5        Bacon     8.0     pig
6     pastrami     3.0     cow
7    honey ham     5.0     pig
8     nova lox     6.0  salmon
============================================
          food  ounces  animal
0        bacon     4.0     pig
1  pulled pork     3.0     pig
2        bacon    12.0     pig
3     Pastrami     6.0     cow
4  corned beef     7.5     cow
5        Bacon     8.0     pig
6     pastrami     3.0     cow
7    honey ham     5.0     pig
8     nova lox     6.0  salmon
```



# 二、Numpy

## 1)、array

=切片的时候，每个参数表示一个维度，比如：array[1:1]：第一行第一列的元素，array[:,1:]：所有行第一列到最后一列的元素；反过来也同理。==

### 1.结构

1.1 如果想要两个不同的数组，需要用copy方法，否则两个数组指向的是同一个数组，则某个数组的改变会导致所有指向这个数组的变量都生效

```Python
tang_array2 = tang_array
tang_array2 = tang_array.copy()
```

1.2 np.where()	传入条件，返回符合条件的索引值

1.3 np.array([1,2,3,4,5],dtype=np.float32)	指定为浮点类型，dtype=xxx

1.4 tang_array.nbytes		数组占用的字节

1.5 np.asarray()	复制一个数组，跟原数组是不同的指向

```python
tang_array = np.array([1,2,3,4,5])
np.asarray(tang_array,dtype = np.float32)
```

1.6 np.ndim()    表示几维

### 2.数值计算

axis为空是表示整个数组，(数组调用的方法)

2.1 求和  np.sum(tang_array,axis=x)，按照某个axis的进行计算，比如：0表示列，1表示行，-1表示最后一个轴

2.2 求乘积	np.prod(tang_array,axis=x) 

2.3 最大、小值	max(tang_array,axis=x)、min(tang_array,axis=x)，

2.4 找到索引的位置 np.argmin(tang_array,axis=x) 

2.5 均值 np.mean(tang_array,axis=x) 

2.6 标准差	np.std(tang_array,axis=x) 

2.7 方差   np.var(tang_array,axis=x) 

2.8 数组值的限制	np..clip(x,y)		小于x的值都变成x，大于y的值都变成y

2.9 近似值	np.round(decimals=x)	decimals表示保留几位小数

### 3.排序

sort():默认最后一个轴排序，可以通过axis指定，同上面一样

argsort():排序后，返回排序前对应的索引值

```Python
array([[1.5, 1.3, 7.5],
       [5.6, 7.8, 1.2]])
np.sort(tang_array)
array([[1.3, 1.5, 7.5],
       [1.2, 5.6, 7.8]])
np.argsort(tang_array)
array([[1, 0, 2],
       [2, 0, 1]])
```

numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None):在指定的间隔范围内返回均匀间隔的数字。在[*start, stop*]范围内计算，返回*num*个(默认为50)均匀间隔的样本。可以选择性地排除间隔的终点。

```Python
tang_array = np.linspace(0,10,10)
tang_array
array([  0.        ,   1.11111111,   2.22222222,   3.33333333,
         4.44444444,   5.55555556,   6.66666667,   7.77777778,
         8.88888889,  10.        ])
>>> np.linspace(2.0, 3.0, num=5)
array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ])
>>> np.linspace(2.0, 3.0, num=5, endpoint=False)
array([ 2. ,  2.2,  2.4,  2.6,  2.8])
>>> np.linspace(2.0, 3.0, num=5, retstep=True)
(array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ]), 0.25)
```

> https://blog.csdn.net/benben_dog/article/details/85446452

```Python
values = np.array([2.5,6.5,9.5])
np.searchsorted(tang_array,values)	# 插入的数组，然后返回对应的索引
array([3, 6, 9], dtype=int64)
```

numpy.lexsort() 	用于对多个序列进行排序，可以实现对数组或列表按照某一行或列进行排序。把它想象成对电子表格进行排序，每一列代表一个序列，排序时优先照顾靠后的列。返回的是对应的索引。

> 注意：返回的是原数组对应的索引

```Python
tang_array = np.array([[1,0,6],
                       [1,7,0],
                       [2,3,1],
                       [2,4,0]])
# -1乘以第一列表示倒序，这里表示先按第一列倒序，再按最后一列升序
index = np.lexsort([-1*tang_array[:,0],tang_array[:,2]])
# index：array([1, 0, 2, 3])
tang_array = tang_array[index]
# 结果
array([[2, 4, 0],
       [1, 7, 0],
       [2, 3, 1],
       [1, 0, 6]])
```

### 4.数组形状操作

大小必须不能改变，即元素个数不能改变

```Python
tang_array = np.arange(10)	# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
tang_array.shape	# (10,)
tang_array.shape = 2,5
# 输出：
array([[0, 1, 2, 3, 4],
       [5, 6, 7, 8, 9]])
tang_array.transpose()	# 等同于tang_array.T，变成5行2列，会生成一个新的array，原始的不会变，要赋值给新的array
#  转置后输出
array([[0, 5],
       [1, 6],
       [2, 7],
       [3, 8],
       [4, 9]])

tang_array.reshape(1,10)	# array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]),转换数组的格式,注意元素个是要与原数组一致，比如换成x行y列
tang_array = tang_array[np.newaxis,:]	# (1, 10)，扩充维度
tang_array = tang_array[:,np.newaxis,np.newaxis]	# (10, 1, 1, 1)
tang_array = tang_array.squeeze()	# 压缩操作，(10,)
```

数组的连接

```Python
a = np.array([[123,456,678],[3214,456,134]])
a.flatten() # 拉平后：array([ 123,  456,  678, 3214,  456,  134])，等同于a.ravel()
b = np.array([[1235,3124,432],[43,13,134]])
c = np.concatenate((a,b))		# 要写成类似元组的格式，即用括号括起来，默认是axis=0，等同于np.vstack((a,b))
# 拼接/连接a，b后输出：
array([[ 123,  456,  678],
       [3214,  456,  134],
       [1235, 3124,  432],
       [  43,   13,  134]])
c = np.concatenate((a,b),axis = 1)	# 等同于np.hstack((a,b))
# 按照第二个维度去拼后输出：
array([[ 123,  456,  678, 1235, 3124,  432],
       [3214,  456,  134,   43,   13,  134]])
```

### 5.数组的生成

构造一个数组：np.arange(10)	或  np.arange(2,20,2)，2-20，步长为2，默认为int，可以通过,dtype=np.float32制定类型

```Python
np.linspace(0,10,10)	#变化一致，从0到10，10个数,等距分布
array([ 0.        ,  1.11111111,  2.22222222,  3.33333333,  4.44444444,
        5.55555556,  6.66666667,  7.77777778,  8.88888889, 10.        ])
x = np.linspace(-10,10,5)	# -10到10，5个数
array([-10.,  -5.,   0.,   5.,  10.])
y = np.linspace(-10,10,5)
x, y= np.meshgrid(x,y)	# 网格,x为一维，y为二维
# 输出 x
array([[-10.,  -5.,   0.,   5.,  10.],
       [-10.,  -5.,   0.,   5.,  10.],
       [-10.,  -5.,   0.,   5.,  10.],
       [-10.,  -5.,   0.,   5.,  10.],
       [-10.,  -5.,   0.,   5.,  10.]])
# 输出 y
array([[-10., -10., -10., -10., -10.],
       [ -5.,  -5.,  -5.,  -5.,  -5.],
       [  0.,   0.,   0.,   0.,   0.],
       [  5.,   5.,   5.,   5.,   5.],
       [ 10.,  10.,  10.,  10.,  10.]])
```

默认是10为底的：

`np.logspace(0,1,5)`	输出：array([  1.        ,   1.77827941,   3.16227766,   5.62341325,  10.        ])

横向量和列向量

```Python
np.r_[0:10:1]		#   array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
np.c_[0:10:1]
# 输出：
array([[0],
       [1],
       [2],
       [3],
       [4],
       [5],
       [6],
       [7],
       [8],
       [9]])
```

都为 0/1向量

```Python
np.zeros(3)		#  array([ 0.,  0.,  0.])
np.zeros((3,3))
# 输出：
array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.],
       [ 0.,  0.,  0.]])
np.ones((3,3))
# 输出：
array([[ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.]])
np.ones((3,3)) * 8
#输出
array([[ 8.,  8.,  8.],
       [ 8.,  8.,  8.],
       [ 8.,  8.,  8.]])
np.ones((3,3),dtype = np.float32)
# 输出：
array([[ 1.,  1.,  1.],
       [ 1.,  1.,  1.],
       [ 1.,  1.,  1.]], dtype=float32)
```

先创建一个空的数组(默认会随机赋值)，然后进行填充：

a = np.empty(6)   

a.fill(1)	都为1

zeros_like和ones_like：赋值同样的维度，并进行赋值0、1

```Python
tang_array = np.array([1,2,3,4])	# array([1, 2, 3, 4])
np.ones_like(tang_array)	# array([1, 1, 1, 1])
np.zeros_like(tang_array) # array([0, 0, 0, 0])
```

单位矩阵，有一对角线全为1

```Python
np.identity(5)
# 输出：
array([[ 1.,  0.,  0.,  0.,  0.],
       [ 0.,  1.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  0.,  0.],
       [ 0.,  0.,  0.,  1.,  0.],
       [ 0.,  0.,  0.,  0.,  1.]])
```

### 6.数组的运算

```Python
y = np.array([1,1,1,4])
x = np.array([1,1,1,2])
x == y
# 输出：
array([ True,  True,  True, False], dtype=bool)
# 与操作
np.logical_and(x,y)
# 输出：
array([ True,  True,  True,  True], dtype=bool)
# 或操作
np.logical_or(x,y)
# 输出
array([ True,  True,  True,  True], dtype=bool)
# 非操作
np.logical_not(x,y)
#输出：array([0, 0, 0, 0])
```

np.multiply（）、np.dot（）和星号（*）

参照：https://blog.csdn.net/itnerd/article/details/83444867

https://blog.csdn.net/zenghaitao0128/article/details/78715140

### 7.随机模块

```Python
#所有的值都是从0到1，构造3行2列的随机数
np.random.rand(3,2)
#返回的是随机的整数，大于等于0，小于10左闭右开，5行4列
np.random.randint(10,size = (5,4))
# 返回一个随机数
np.random.rand()
# 0到10，选3个数，1行3列
np.random.randint(0,10,3)
# 高斯分布
mu, sigma = 0,0.1
np.random.normal(mu,sigma,10)
# 设置精度为2位
np.set_printoptions(precision = 2)
# 打乱顺序
tang_array = np.arange(10)	# array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
np.random.shuffle(tang_array)	# array([6, 2, 5, 7, 4, 3, 1, 0, 8, 9])
# 随机的种子，指定了种子之后，下次执行的随机值会固定，调节其他参数对结果的影响的时候，可以通过设置种子，保证其他参数对结果的影响不变
np.random.seed(100)
mu, sigma = 0,0.1
np.random.normal(mu,sigma,10)
# 上面三行执行结果(一直都是)：
array([-0.17,  0.03,  0.12, -0.03,  0.1 ,  0.05,  0.02, -0.11, -0.02,
        0.03])
```

### 8.读写文件

原生Python读写文件：

```Python
%%writefile tang.txt
1 2 3 4 5 6
2 3 5 8 7 9
data = []
# with语句可以自动帮我们调用close()方法，与try ... finally作用一样
with open('tang.txt') as f:
    for line in f.readlines():
        fileds = line.split()
        cur_data = [float(x) for x in fileds]
        data.append(cur_data)
data = np.array(data)
# 输出：
array([[ 1.,  2.,  3.,  4.,  5.,  6.],
       [ 2.,  3.,  5.,  8.,  7.,  9.]])
```

numpy读写文件：

- 'tang2.txt':路径最好放到和代码一起
- skiprows : 去掉几行
- delimiter = ',' :分隔符
- usecols = (0,1,4) ：指定使用哪几列

```Python
data = np.loadtxt('tang.txt')
#输出data：
array([[ 1.,  2.,  3.,  4.,  5.,  6.],
       [ 2.,  3.,  5.,  8.,  7.,  9.]])
%%writefile tang2.txt
1,2,3,4,5,6
2,3,5,8,7,9
data = np.loadtxt('tang2.txt',delimiter = ',')
# 输出data：
array([[ 1.,  2.,  3.,  4.,  5.,  6.],
       [ 2.,  3.,  5.,  8.,  7.,  9.]])
%%writefile tang2.txt
x,y,z,w,a,b
1,2,3,4,5,6
2,3,5,8,7,9
data = np.loadtxt('tang2.txt',delimiter = ',',skiprows = 1)
# 输出：
array([[ 1.,  2.,  3.,  4.,  5.,  6.],
       [ 2.,  3.,  5.,  8.,  7.,  9.]])
```

保存数组生成文件：

```Python
tang_array = np.array([[1,2,3],[4,5,6]])
# 逗号分隔，格式是整数，默认是科学计数法
np.savetxt('tang4.txt',tang_array,fmt='%d',delimiter = ',')
# 生成的文件：
1,2,3
4,5,6
np.savetxt('tang4.txt',tang_array,fmt='%.2f',delimiter = ',')
# 生成的文件：
1.00,2.00,3.00
4.00,5.00,6.00
```

读写array结构：

```Python
tang_array = np.array([[1,2,3],[4,5,6]])
np.save('tang_array.npy',tang_array)	#  保存为文件
tang = np.load('tang_array.npy')
# 输出tang
array([[1, 2, 3],
       [4, 5, 6]])
##############################
tang_array2 = np.arange(10)
np.savez('tang.npz',a=tang_array,b=tang_array2)		# 类似压缩文件，指定a和b各自对应一个数组，解压后分别是a.py和b.py
data = np.load('tang.npz')
data.keys()			#  输出：['a', 'b']
data['a']
# 输出
array([[1, 2, 3],
       [4, 5, 6]])
data['b']
# 输出
array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])
```

### 练习题

```Python
import numpy as np
# 构造一个全零的矩阵，并打印其占用的内存大小
z = np.zeros((5,5))
print(('%d bytes'%(z.size*z.itemsize)))		#  输出200 bytes，矩阵的大小(5*5=25)乘以矩阵中每个元素所占用的大小(一个8字节)

# 创建一个10-49的数组，并将其倒序排列
data = np.arange(10,50,1)
data = data[::-1]

# 找到一个数组中不为0的索引
np.nonzero([1,2,3,4,5,0,0,0,1234,0,1])
# 输出：(array([ 0,  1,  2,  3,  4,  8, 10], dtype=int64),)

# 随机构造一个3*3矩阵，并打印其中最大与最小值
tang_array = np.random.random((3,3))
tang_array.min()
tang_array.max()

# 构造一个5*5的矩阵，令其值都为1，并在最外层加上一圈0,即边缘填充
tang_array = np.ones((5,5))
# 
tang_array = np.pad(tang_array,pad_width = 1,mode = 'constant',constant_values = 0)
tang_array
# 输出：
array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],
       [ 0.,  0.,  1.,  1.,  1.,  1.,  1.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],
       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])

# 构建一个shape为（6，7，8）的矩阵，并找到第100个元素的索引值
np.unravel_index(100,(6,7,8))

# 对一个5*5的矩阵做归一化操作
tang_array = np.random.random((5,5))
tang_max = tang_array.max()
tang_min = tang_array.min()
# 归一化即把数据变成(０，１)或者（1,1）之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速
# 这里用数组中每个值与最小值的差值除以数组中最大值和最小值之间的差值作为归一化的结果
tang_array = (tang_array-tang_min)/(tang_max - tang_min)
tang_array

# 找到两个数组中相同的值
z1 = np.random.randint(0,10,10) 
z2 = np.random.randint(0,10,10)
print (z1)
print (z2)
print (np.intersect1d(z1,z2))

# 得到一个数的整数部分
z = np.random.uniform(0,10,10)	# 0-10,10个实数
np.floor(z)

# 构造一个数组，让它不能被改变
z = np.zeros(5)
z.flags.writeable = False

# 打印数据的部分值，全部值
np.set_printoptions(threshold=5)	# 打印选项，设置了阈值为5
z = np.zeros((15,15))

# 找到在一个数组中，最接近一个数的索引
z = np.arange(100)
v = np.random.uniform(0,100)
index = (np.abs(z-v)).argmin()	# 看z数组中最接近v的值，找绝对值中最小的，即距离最近的，注意返回的是索引。

# 32位float类型和32位int类型转换
z = np.arange(10,dtype=np.int32)
z = z.astype(np.float32)

# 打印数组元素位置坐标与数值,通过numpy的枚举操作
z = np.arange(9).reshape(3,3)
for index,value in np.ndenumerate(z):
    print (index,value)
    
#按照数组的某一列进行排序
z = np.random.randint(0,10,(3,3))
print (z[z[:,1].argsort()])	# 这里是按第二列进行排序，然后通过返回排序后的索引，将排序后的数组打印

# 统计数组中每个数值出现的次数
z = np.array([1,1,1,2,2,3,3,4,5,8])
np.bincount(z)

# 对一个四维数组的最后两维来求和
z = np.random.randint(0,10,(4,4,4,4))
res = z.sum(axis=(-2,-1))		# 后面两个轴

# 交换矩阵中的两行
z = np.arange(25).reshape(5,5)
z[[0,1]] = z[[1,0]]		# 这里交换的是一二行

# 找到一个数组中最常出现的数字
z = np.random.randint(0,10,50)
np.bincount(z).argmax()		# 先统计每个数组出现的次数，再找到最多的

# 快速查找TOP K
z = np.arange(10000)
np.random.shuffle(z)	# 洗牌
n = 5
print (z[np.argpartition(-z,n)[:n]])		# argpartition快速排序的方法，取前n个，然后再打印出来

# 去除掉一个数组中，所有元素都相同的数据
np.set_printoptions(threshold=np.nan)		# 全部打印
z = np.random.randint(0,3,(10,3))
e = np.all(z[:,1:] == z[:,:-1],axis = 1)	# axis = 1，一行一行判断，返回的是每一行的结果
# 输出e：[False False False  True False False False False False False]
a = np.array([1,2,3,4])
b = np.array([1,2,3,5])
np.all(a == b)		# 返回False，判断是否都一样
np.any(a == b)    # 返回True，只要有一个一样即可
```

# 三、Pandas

## 1、简介

### 文件的读取

```Python
import pandas as pd
df = pd.read_csv('./data/titanic.csv')
# .head()可以读取前几条数据,指定前几条都可以
df.head(6)		# 读取前六行，如果不传参数默认是读取前5行

# .info返回当前的信息,即接收读取到的文件的变量所代表的的信息，包括df的结构、列名、数据类型等
df.info()
###############################输出：################################
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
PassengerId    891 non-null int64
Survived       891 non-null int64
Pclass         891 non-null int64
Name           891 non-null object
Sex            891 non-null object
Age            714 non-null float64
SibSp          891 non-null int64
Parch          891 non-null int64
Ticket         891 non-null object
Fare           891 non-null float64
Cabin          204 non-null object
Embarked       889 non-null object
dtypes: float64(2), int64(5), object(5)
memory usage: 83.6+ KB
###############################输出：################################
df.index			#  输出：RangeIndex(start=0, stop=891, step=1)
df.columns		# 输出列名
df.dtypes			# 各列数据类型
df.values			# 每一行数据
# 取指定的数据，比如下面这个是取Age这一列的值,返回的是一个Series类型的变量，表示dataframe中的一行/列
age = df['Age']		
age[:5]			# 取前5行，如果输出NaN，表示为空
age.index	# 输出：RangeIndex(start=0, stop=891, step=1)
# 相当于：df['Age'][:5]

# 指定Name那一列作为索引,原先没有索引，默认是阿拉伯数字
df = df.set_index('Name')
age = df['Age']
age['Allen, Mr. William Henry']		#  通过指定的索引，找到对应的值
# 对结果进行运算,不改变原来的数据：
age = age + 10
age = age *10 
age.mean()
age.max()
age.min()
#.describe()可以得到数据的基本统计特性，包括总计、标准差等
df.describe()
```

![image-20201118205121797](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201118205121797.png)

![image-20201118205411915](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201118205411915.png)

### DataFrame

```Python
# 创建一个DataFrame，指定列名
data = {'country':['aaa','bbb','ccc'],
       'population':[10,12,14]}
df_data = pd.DataFrame(data)
```

## 2、索引

```Python
# 获取Age和Fare这两列的前5行
df[['Age','Fare']][:5]
# 定位具体数据：loc 用label(列名或者自定义的索引值)来去定位；iloc 用position来去定位
df.iloc[0]  #  第一行的所有列的数据
df.iloc[0:5]		#  1-5行的所有列的数据
df.iloc[0:5,1:3]  # 1-5行、2-3列数据，左闭右开，索引值对应行列数要减一

# 设置索引后，通过索引获取
df = df.set_index('Name')
df.loc['Heikkinen, Miss. Laina']
df.loc['Heikkinen, Miss. Laina','Fare']		#  费用
```

![image-20201118210314802](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201118210314802.png)

```Python
# bool类型的索引
df['Fare'] > 40		#  返回布尔类型的索引
df[df['Fare'] > 40][:5]		# 大于40的前5行
df[df['Sex'] == 'male'][:5]
df.loc[df['Sex'] == 'male','Age'].mean()		# male里面年龄的平均值
(df['Age'] > 70).sum()		# 大于70的数量
```

## 3、groupby

对数据进行分组，可以再进行对应的操作

```Python
df = pd.DataFrame({'key':['A','B','C','A','B','C','A','B','C'],
                  'data':[0,5,10,5,10,15,10,15,20]})
df.groupby('key').sum()		# 	按key分组，然后再求和，即对A,B,C分别求和
# 执行numpy的操作
df.groupby('key').aggregate(np.mean)	# 求均值
# 读取上面的文件数据
df = pd.read_csv('./data/titanic.csv')
# 按性别分组，然后求年龄和存活人的平均值
df.groupby('Sex')['Age'].mean()
df.groupby('Sex')['Survived'].mean()
```

## 4、数值运算

```Python
import pandas as pd
# 指定了索引
df = pd.DataFrame([[1,2,3],[4,5,6]],index = ['a','b'],columns = ['A','B','C'])
#####################################输出：####################################
	A	B	C
a	1	2	3
b	4	5	6
############################################################
# 默认都是按列进行计算的
df.sum()		# 默认按列进行求和，即axis=0
# 输出：
A    5
B    7
C    9
dtype: int64
df.sum(axis = 1)		#  按行求和，等于axis = 'columns'
# 输出：
a     6
b    15
dtype: int64
# 默认都是按列计算
df.mean()
df.min()
df.max()	
df.median()		#	中位数
```

二元统计(特征之间的关系)

```Python
df = pd.read_csv('./data/titanic.csv')
df.cov()	# 协方差，反映数据分布规则
df.corr()		# 相关系数，特征之间的相关性，如果相关性太强可能要排除
#  统计不同年龄值的人数，默认降序，可以改为升序；bins=5:将所有年龄平均分为5组；bins可用于分组
df['Age'].value_counts(ascending = True,bins = 5)		
```

![image-20201118214030662](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201118214030662.png)

![image-20201118214108451](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201118214108451.png)

## 5、对象操作

### Series结构的增删改查

```Python
data = [10,11,12]
index = ['a','b','c']
s = pd.Series(data = data,index = index)
###################输出： ##### ##### ##### ##### ##### ##### #####
a    10
b    11
c    12
dtype: int64
##################
s[0]   # 10
s[0:2]  #  相当于mask = [True,True,False]	s[mask]
# 输出：
a    10
b    11
dtype: int64

s.loc['b']	# 11,等同于   s.iloc[1]	第二行

# 改操作
s1 = s.copy()
s1['a'] = 100   # s1的索引a对应的值变成100，但是原来的s不变
# 将所有值为100的都改成101，inplace表示要不要改变原来的s1，如果为False，则s1的值不变
s1.replace(to_replace = 100,value = 101,inplace = True)	
# 索引的修改
s1.index # Index(['a', 'b', 'c'], dtype='object')
s1.index = ['a','b','d']		# 将索引c改成d
s1.rename(index = {'a':'A'},inplace = True)		# 将索引a改成A

# 增操作,默认是保留原来的索引，如果改为True则生成新的索引
s3 = s1.append(s2,ignore_index = True)  # 将两个Series拼接到一起

# 删操作
del s1['A']   # 删除s1中索引A对应的值
s1.drop(['b','c'],inplace = True)		# 在原来的数据上删除b、c 
```

### DataFrame结构的增删改查

```Python
data = [[1,2,3],[4,5,6]]
index = ['a','b']
columns = ['A','B','C']
# 构造DataFrame数据
df = pd.DataFrame(data=data,index=index,columns = columns)
# 查、改操作类似Series，只是多了一维
df.loc['c'] = [1,2,3]   #  增加多一行
df3 = pd.concat([df,df2],axis = 0)	#连接两个DataFrame，默认是竖着拼，axis=1为横着拼
df['f'] = [1,2]	#  增加一列
df4 = pd.DataFrame([[10,11],[12,13]],index=['j','k'],columns=['D','E'])

# 删操作
df5.drop(['j'],axis=0,inplace = True)	# 删除j行
del df5['Tang']		# 删除Tang这一列
df5.drop(['A','B','C'],axis = 1,inplace = True) # 删除A,B,C这三列
```

## 6、merge操作

默认以相同的键(即索引/列名)进行合并，将两个DataFrame进行合并。一般用于分模块提取特征，然后再进行合并。

```Python
# left和right都有相同的列名：key1，以key1位键进行合并，如果还有相同的列的话，会以key_x进行区分
pd.merge(left,right,on='key1')
# how=outer表示不是共有也要列举出来，指示器indicator = True表示会把每个数据的情况都列出：共有还是某个特有
pd.merge(left,right,on=['key1','key2'],how='outer',indicator = True)
# 以left这个DataFrame为主
pd.merge(left,right,on=['key1','key2'],how='left')
```

![image-20201119212202109](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119212202109.png)

![image-20201119212357980](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119212357980.png)

![image-20201119212703241](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119212703241.png)

## 7、显示设置

[设置参数](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.set_option.html?highlight=set_option#pandas.set_option)

```Python
# 获取默认显示的最多行数、列数
pd.get_option('display.max_rows')		#  默认60
pd.set_option('display.max_rows',6)	# 设置显示6行，前后各3行，如果是奇数的话，则显示奇数-1行
# pd.Series(index = range(0,7))
pd.get_option('display.max_columns')		# 默认20
pd.set_option('display.max_columns',30)	# 显示30列
# 字符串最大打印的长度
pd.get_option('display.max_colwidth')	# 默认50
pd.Series(index = ['A'],data=['t'*120])  # 超过50则会用省略号表示
# 保留几位小数
pd.get_option('display.precision')	# 默认6位
pd.Series(data = [1.23456789236546])		# 0    1.234568
pd.set_option('display.precision',5)
```

## 8、数据透视表

将数据按照设定的格式进行展示

```Python
import pandas as pd
example = pd.DataFrame({'Month': ["January", "January", "January", "January", 
                                  "February", "February", "February", "February", 
                                  "March", "March", "March", "March"],
                   'Category': ["Transportation", "Grocery", "Household", "Entertainment",
                                "Transportation", "Grocery", "Household", "Entertainment",
                                "Transportation", "Grocery", "Household", "Entertainment"],
                   'Amount': [74., 235., 175., 100., 115., 240., 225., 125., 90., 260., 200., 120.]})
```

![image-20201119220812752](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119220812752.png)

```Python
# 以Category为键(索引)，Month为列，Amount为数据
example_pivot = example.pivot(index = 'Category',columns= 'Month',values = 'Amount')
```

![image-20201119220859442](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119220859442.png)

```Python
# 按索引(即键/行)进行统计
example_pivot.sum(axis = 1)
Category
Entertainment     345.0
Grocery           735.0
Household         600.0
Transportation    279.0
dtype: float64
# 按列进行统计，统计不同月份的花销
example_pivot.sum(axis = 0)
Month
February    705.0
January     584.0
March       670.0
dtype: float64
  
df = pd.read_csv('./data/titanic.csv')
#默认值就是求平均，这里的值是Fare,列是船舱等级,索引是性别，表示一、二和三等舱男性、女性价格的平均值
df.pivot_table(index = 'Sex',columns='Pclass',values='Fare')
# 通过aggfunc指定获取不同的标准,max:最大值;count:数量;mean:平均数
df.pivot_table(index = 'Sex',columns='Pclass',values='Fare',aggfunc='max')
# 输出：
Pclass	1					2				3
Sex			
female	512.3292	65.0	69.55
male	512.3292	73.5	69.55
# 计数，等同于上面aggfunc取count,即统计一、二和三等舱男性、女性价格的人数
pd.crosstab(index = df['Sex'],columns = df['Pclass'])
# 船舱等级与性别获救的平均几率
df.pivot_table(index = 'Pclass',columns='Sex',values='Survived',aggfunc='mean')
# 输出：

Sex	 female			male
Pclass		
1		0.968085	0.368852
2		0.921053	0.157407
3		0.500000	0.135447

# 指定未成年的列，并赋作索引
df['Underaged'] = df['Age'] <= 18
df.pivot_table(index = 'Underaged',columns='Sex',values='Survived',aggfunc='mean')
```

## 9、时间序列操作

```Python
import pandas as pd
# 去第一列作为索引，转换日期格式
data = pd.read_csv('./data/flowdata.csv',index_col = 0,parse_dates = True)
data.head()
# 输出：	
										 L06_347	 LS06_347	 LS06_348
Time			
2009-01-01 00:00:00	0.137417	0.097500	0.016833
2009-01-01 03:00:00	0.131250	0.088833	0.016417
2009-01-01 06:00:00	0.113500	0.091250	0.016750
2009-01-01 09:00:00	0.135750	0.091500	0.016250
2009-01-01 12:00:00	0.140917	0.096167	0.017000
# 切片操作：
data[pd.Timestamp('2012-01-01 09:00'):pd.Timestamp('2012-01-01 19:00')]
# 与上面等同
data[('2012-01-01 08:59'):('2012-01-01 19:00')]
# 取2013年的数据
data['2013']
data['2012-01':'2012-03']
# 取所有年份中的一月份，从索引中取月份
data[data.index.month == 1]
#  取所有时间数据中8-12点的数据，与between_time作用相同
data[(data.index.hour > 8) & (data.index.hour <12)] # data.between_time('08:00','12:00')
# 重采样，以一天(D)为单位,或3D，3天
data.resample('D').mean().head()
```

## 9、常用操作

```Python
# 构建数据
data = pd.DataFrame({'group':['a','a','a','b','b','b','c','c','c'],
                    'data':[4,3,2,1,12,3,4,5,7]})
# 按group和data分组，第一列为group，第二列为data，先按group降序，后按data升序
data.sort_values(by=['group','data'],ascending = [False,True],inplace=True)
# 输出：
	data	group
6	 4	 		c
7	 5			c
8	 7			c
3	 1			b
5	 3			b
4	 12			b
2	 2			a
1	 3			a
0	 4			a
# 构建数据：
data = pd.DataFrame({'k1':['one']*3+['two']*4,
                   'k2':[3,2,1,3,3,4,4]})
# 按k2排序
data.sort_values(by='k2')
  k1	k2
2	one	1
1	one	2
0	one	3
3	two	3
4	two	3
5	two	4
6	two	4
# 删除重复的值，即k1,k2对应的值一样；如果传入subset='k1'，则删除k1中重复的值
data.drop_duplicates()
# 输出：
  k1	k2
0	one	3
1	one	2
2	one	1
3	two	3
5	two	4

data = pd.DataFrame({'food':['A1','A2','B1','B2','B3','C1','C2'],
                     'data':[1,2,3,4,5,6,7]})
# 定义一个方法：
def food_map(series):
    if series['food'] == 'A1':
        return 'A'
    elif series['food'] == 'A2':
        return 'A'
    elif series['food'] == 'B1':
        return 'B'
    elif series['food'] == 'B2':
        return 'B'
    elif series['food'] == 'B3':
        return 'B'
    elif series['food'] == 'C1':
        return 'C'
    elif series['food'] == 'C2':
        return 'C'
# 追加一列：food_map；传入自定义函数，对每一列都执行这个函数；apply指定函数
data['food_map'] = data.apply(food_map,axis = 'columns')
food2Upper = {
    'A1':'A',
    'A2':'A',
    'B1':'B',
    'B2':'B',
    'B3':'B',
    'C1':'C',
    'C2':'C'
}
# 用map追加一列，其中food2Upper对应food这一列的值；map指定一个字典
data['upper'] = data['food'].map(food2Upper)
```

![image-20201119230826263](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119230826263.png)

![image-20201119230939106](https://learningpics.oss-cn-shenzhen.aliyuncs.com/images/image-20201119230939106.png)

```Python
import numpy as np
df = pd.DataFrame({'data1':np.random.randn(5),
                  'data2':np.random.randn(5)})
# 指定比例(ration)这一列，作为新特征/新的值
df2 = df.assign(ration = df['data1']/df['data2'])
# 输出：
		data1			data2		ration
0	-1.069925	-0.186540	5.735617
1	0.636127	0.020425	31.143814
2	0.366197	-0.102836	-3.560992
3	-0.975327	0.451201	-2.161624
4	-1.562407	-2.436845	0.641160
# 删除ration这一列
df2.drop('ration',axis='columns',inplace=True)
# 将9这个值替换为np.nan，即NaN
data.replace(9,np.nan,inplace=True)
# 对数组age进行离散处理，分区间
ages = [15,18,20,21,22,34,41,52,63,79]
bins = [10,40,80]
bins_res = pd.cut(ages,bins)
# 输出：
[(10, 40], (10, 40], (10, 40], (10, 40], (10, 40], (10, 40], (40, 80], (40, 80], (40, 80], (40, 80]]
Categories (2, interval[int64]): [(10, 40] < (40, 80]]
pd.value_counts(bins_res)
# 输出：
(10, 40]    6
(40, 80]    4
dtype: int64
# 分成3个组
pd.cut(ages,[10,30,50,80])
# 输出：
[(10, 30], (10, 30], (10, 30], (10, 30], (10, 30], (30, 50], (30, 50], (50, 80], (50, 80], (50, 80]]
Categories (3, interval[int64]): [(10, 30] < (30, 50] < (50, 80]]
# 指定组名
group_names = ['Yonth','Mille','Old']
pd.value_counts(pd.cut(ages,[10,20,50,80],labels=group_names))
# 输出：
Mille    4
Old      3
Yonth    3
dtype: int64
                                                         
df = pd.DataFrame([range(3),[0, np.nan,0],[0,0,np.nan],range(3)])
# 找出缺失值
df.isnull()                                                         
		0			1			2
0	False	False	False
1	False	True	False
2	False	False	True
3	False	False	False                                                         

# 默认按列统计，只要有一个为True，则返回True
df.isnull().any()                                                         
0    False
1     True
2     True
dtype: bool
# 指定按行
df.isnull().any(axis = 1)                                                         
0    False
1     True
2     True
3    False
dtype: bool                                                         
                                                         
# 填充缺失值，这里用5去填充
df.fillna(5)
#  返回按列统计时为True的数据                                                                                                                
df[df.isnull().any(axis = 1)]   
# 输出：
	0		1	 		2
1	0	NaN		0.0
2	0	0.0		NaN                                                         
```







